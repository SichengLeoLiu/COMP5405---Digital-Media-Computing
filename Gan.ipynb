{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.utils as vutils\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import glob\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import vgg19, resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_features, in_features, kernel_size=3, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(in_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_features, in_features, kernel_size=3, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(in_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Initial convolution block\n",
    "        model = [\n",
    "            nn.Conv2d(input_nc, 64, kernel_size=7, padding=3, bias=False),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features*2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features*2\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        # Upsampling\n",
    "        out_features = in_features//2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.ConvTranspose2d(in_features, out_features, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features//2\n",
    "\n",
    "        # Output layer\n",
    "        model += [nn.Conv2d(64, output_nc, kernel_size=7, padding=3), nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        model = [\n",
    "            nn.Conv2d(input_nc, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "\n",
    "        model += [\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "\n",
    "        model += [\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "\n",
    "        model += [\n",
    "            nn.Conv2d(256, 512, kernel_size=4, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "\n",
    "        model += [nn.Conv2d(512, 1, kernel_size=4, padding=1)]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(int(256*1.12), Image.BICUBIC),\n",
    "    transforms.RandomCrop(256),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root='data', transforms_=None, unaligned=False, mode=\"train\"):          ## (root = \"./datasets/facades\", unaligned=True:非对其数据)\n",
    "        self.transform = transforms_                             ## transform变为tensor数据\n",
    "        self.unaligned = unaligned\n",
    "\n",
    "        self.files_A = sorted(glob.glob(os.path.join(root, \"%sA\" % mode) + \"/*.*\"))     ## \"./datasets/facades/trainA/*.*\"\n",
    "        self.files_B = sorted(glob.glob(os.path.join(root, \"%sB\" % mode) + \"/*.*\"))     ## \"./datasets/facades/trainB/*.*\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_A = Image.open(self.files_A[index % len(self.files_A)])                   ## 在A中取一张照片\n",
    "\n",
    "        if self.unaligned:                                                              ## 如果采用非配对数据，在B中随机取一张\n",
    "            image_B = Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)])\n",
    "        else:\n",
    "            image_B = Image.open(self.files_B[index % len(self.files_B)])\n",
    "\n",
    "        # # 如果是灰度图，把灰度图转换为RGB图\n",
    "        # if image_A.mode != \"RGB\":\n",
    "        #     image_A = to_rgb(image_A)\n",
    "        # if image_B.mode != \"RGB\":\n",
    "        #     image_B = to_rgb(image_B)\n",
    "        \n",
    "        # 把RGB图像转换为tensor图, 方便计算，返回字典数据\n",
    "        item_A = self.transform(image_A)\n",
    "        item_B = self.transform(image_B)\n",
    "        return item_A, item_B\n",
    "\n",
    "    ## 获取A,B数据的长度\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_A), len(self.files_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(        ## 改成自己存放文件的目录\n",
    "    ImageDataset(\"human_dog\", transforms_=transform, unaligned=True, mode=\"train\"),  ## \"./datasets/facades\" , unaligned:设置非对其数据\n",
    "    batch_size=4,                                                                  ## batch_size = 1\n",
    "    shuffle=True,\n",
    ")\n",
    "test_dataloader = DataLoader(        ## 改成自己存放文件的目录\n",
    "    ImageDataset(\"human_dog\", transforms_=transform, unaligned=True, mode=\"test\"),  ## \"./datasets/facades\" , unaligned:设置非对其数据\n",
    "    batch_size=4,                                                                  ## batch_size = 1\n",
    "    shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "G_AB = Generator(input_nc=3, output_nc=3).to(device)\n",
    "G_BA = Generator(input_nc=3, output_nc=3).to(device)\n",
    "D_A = Discriminator(input_nc=3).to(device)\n",
    "D_B = Discriminator(input_nc=3).to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=0.0005, betas=(0.5, 0.999))\n",
    "optimizer_D_A = Adam(D_A.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
    "optimizer_D_B = Adam(D_B.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
    "\n",
    "# Losses\n",
    "criterion_GAN = nn.MSELoss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_identity = nn.L1Loss()\n",
    "\n",
    "\n",
    "output_dir = './cyclegan_images'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss_G: 15.61037826538086, Loss_D_A: 1.1615573167800903, Loss_D_B: 0.9101475477218628\n",
      "Epoch: 0, Batch: 10, Loss_G: 6.970175743103027, Loss_D_A: 0.3666701912879944, Loss_D_B: 0.24359501898288727\n",
      "Epoch: 0, Batch: 20, Loss_G: 5.965689659118652, Loss_D_A: 0.24649454653263092, Loss_D_B: 0.24288181960582733\n",
      "Epoch: 0, Batch: 30, Loss_G: 5.182547569274902, Loss_D_A: 0.24978424608707428, Loss_D_B: 0.2856913208961487\n",
      "Epoch: 0, Batch: 40, Loss_G: 7.472266674041748, Loss_D_A: 0.3758556544780731, Loss_D_B: 0.32502102851867676\n",
      "Epoch: 0, Batch: 50, Loss_G: 7.623085975646973, Loss_D_A: 0.23080357909202576, Loss_D_B: 0.24449694156646729\n",
      "Epoch: 0, Batch: 60, Loss_G: 6.9660868644714355, Loss_D_A: 0.26649582386016846, Loss_D_B: 0.23975417017936707\n",
      "Epoch: 0, Batch: 70, Loss_G: 5.563512325286865, Loss_D_A: 0.24589692056179047, Loss_D_B: 0.2512208819389343\n",
      "Epoch: 0, Batch: 80, Loss_G: 6.209434986114502, Loss_D_A: 0.30268868803977966, Loss_D_B: 0.2863529324531555\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(4):\n",
    "    for i, (real_A, real_B) in enumerate(train_dataloader):\n",
    "        real_A = real_A.to(device)\n",
    "        real_B = real_B.to(device)\n",
    "\n",
    "        # 训练生成器 G_A 和 G_B\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # 对抗性损失\n",
    "        fake_B = G_AB(real_A)\n",
    "        pred_fake = D_B(fake_B)\n",
    "        loss_GAN_A2B = criterion_GAN(pred_fake, torch.ones_like(pred_fake))\n",
    "        \n",
    "        fake_A = G_BA(real_B)\n",
    "        pred_fake = D_A(fake_A)\n",
    "        loss_GAN_B2A = criterion_GAN(pred_fake, torch.ones_like(pred_fake))\n",
    "        \n",
    "        # 循环一致性损失\n",
    "        recovered_A = G_BA(fake_B)\n",
    "        loss_cycle_ABA = criterion_cycle(recovered_A, real_A) * 10.0\n",
    "        \n",
    "        recovered_B = G_AB(fake_A)\n",
    "        loss_cycle_BAB = criterion_cycle(recovered_B, real_B) * 10.0\n",
    "\n",
    "        # 总损失\n",
    "        loss_G = loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # 训练判别器 D_A\n",
    "        optimizer_D_A.zero_grad()\n",
    "\n",
    "        pred_real = D_A(real_A)\n",
    "        loss_D_real = criterion_GAN(pred_real, torch.ones_like(pred_real))\n",
    "\n",
    "        pred_fake = D_A(fake_A.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, torch.zeros_like(pred_fake))\n",
    "\n",
    "        # 总损失\n",
    "        loss_D_A = (loss_D_real + loss_D_fake) * 0.5\n",
    "        loss_D_A.backward()\n",
    "        optimizer_D_A.step()\n",
    "\n",
    "        # 训练判别器 D_B\n",
    "        optimizer_D_B.zero_grad()\n",
    "\n",
    "        pred_real = D_B(real_B)\n",
    "        loss_D_real = criterion_GAN(pred_real, torch.ones_like(pred_real))\n",
    "\n",
    "        pred_fake = D_B(fake_B.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, torch.zeros_like(pred_fake))\n",
    "\n",
    "        # 总损失\n",
    "        loss_D_B = (loss_D_real + loss_D_fake) * 0.5\n",
    "        loss_D_B.backward()\n",
    "        optimizer_D_B.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f'Epoch: {epoch}, Batch: {i}, Loss_G: {loss_G.item()}, Loss_D_A: {loss_D_A.item()}, Loss_D_B: {loss_D_B.item()}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 使用测试集中的数据生成图像\n",
    "        for i, (real_A, real_B) in enumerate(test_dataloader):\n",
    "            real_A = real_A.to(device)\n",
    "            fake_B = G_AB(real_A)\n",
    "            vutils.save_image(fake_B, f'{output_dir}/fake_B_epoch_{epoch}_batch_{i}.png', normalize=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN Inversion\n",
    "\n",
    "Train the model to convert A to A. Then interpolation can be used to generate intermediate image. \n",
    "\n",
    "Using contrastive loss to make the model to learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root='data', transforms_=None, unaligned=False, mode=\"train\"):          ## (root = \"./datasets/facades\", unaligned=True:非对其数据)\n",
    "        self.transform = transforms_                             ## transform变为tensor数据\n",
    "        self.unaligned = unaligned\n",
    "\n",
    "        self.files_A = sorted(glob.glob(os.path.join(root, 'combined') + \"/*.*\"))     ## \"./datasets/facades/trainA/*.*\"\n",
    "        self.files_B = sorted(glob.glob(os.path.join(root, 'combined') + \"/*.*\"))     ## \"./datasets/facades/trainB/*.*\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_A = Image.open(self.files_A[index % len(self.files_A)])                   ## 在A中取一张照片\n",
    "\n",
    "        if self.unaligned:                                                              ## 如果采用非配对数据，在B中随机取一张\n",
    "            image_B = Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)])\n",
    "        else:\n",
    "            image_B = Image.open(self.files_B[index % len(self.files_B)])\n",
    "\n",
    "        # # 如果是灰度图，把灰度图转换为RGB图\n",
    "        # if image_A.mode != \"RGB\":\n",
    "        #     image_A = to_rgb(image_A)\n",
    "        # if image_B.mode != \"RGB\":\n",
    "        #     image_B = to_rgb(image_B)\n",
    "        \n",
    "        # 把RGB图像转换为tensor图, 方便计算，返回字典数据\n",
    "        item_A = self.transform(image_A)\n",
    "        item_B = self.transform(image_B)\n",
    "        return item_A, item_B\n",
    "\n",
    "    ## 获取A,B数据的长度\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_A), len(self.files_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(        ## 改成自己存放文件的目录\n",
    "    ImageDataset(\"human_dog\", transforms_=transform, unaligned=True, mode=\"train\"),  ## \"./datasets/facades\" , unaligned:设置非对其数据\n",
    "    batch_size=16,                                                                  ## batch_size = 1\n",
    "    shuffle=True,\n",
    ")\n",
    "test_dataloader = DataLoader(        ## 改成自己存放文件的目录\n",
    "    ImageDataset(\"human_dog\", transforms_=transform, unaligned=True, mode=\"test\"),  ## \"./datasets/facades\" , unaligned:设置非对其数据\n",
    "    batch_size=16,                                                                  ## batch_size = 1\n",
    "    shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_features, in_features, kernel_size=3, padding=1, bias=False)\n",
    "        self.norm1 = nn.InstanceNorm2d(in_features)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(in_features, in_features, kernel_size=3, padding=1, bias=False)\n",
    "        self.norm2 = nn.InstanceNorm2d(in_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "        return identity + out\n",
    "\n",
    "class DownsampleBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(DownsampleBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.norm = nn.InstanceNorm2d(out_features)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(UpsampleBlock, self).__init__()\n",
    "        self.conv = nn.ConvTranspose2d(in_features, out_features, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.norm = nn.InstanceNorm2d(out_features)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "        self.initial_conv = nn.Sequential(\n",
    "            nn.Conv2d(input_nc, 64, kernel_size=7, padding=3, bias=False),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.downsample_blocks = nn.ModuleList([\n",
    "            DownsampleBlock(64, 128),\n",
    "            DownsampleBlock(128, 256)\n",
    "        ])\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(256) for _ in range(n_residual_blocks)]\n",
    "        )\n",
    "        self.upsample_blocks = nn.ModuleList([\n",
    "            UpsampleBlock(256, 128),\n",
    "            UpsampleBlock(128, 64)\n",
    "        ])\n",
    "        self.output_conv = nn.Sequential(\n",
    "            nn.Conv2d(64, output_nc, kernel_size=7, padding=3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial_conv(x)\n",
    "        \n",
    "        for down_block in self.downsample_blocks:\n",
    "            x = down_block(x)\n",
    "        x = self.residual_blocks(x)\n",
    "        for up_block in self.upsample_blocks:\n",
    "            x = up_block(x)\n",
    "        x = self.output_conv(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "G_AA = Generator(input_nc=4, output_nc=3).to(device)\n",
    "# G_BA = Generator(input_nc=3, output_nc=3).to(device)\n",
    "D_A = Discriminator(input_nc=3).to(device)\n",
    "D_B = Discriminator(input_nc=3).to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = Adam(G_AA.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
    "optimizer_D_A = Adam(D_A.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
    "optimizer_D_B = Adam(D_B.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
    "\n",
    "# Losses\n",
    "criterion_GAN = nn.MSELoss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_identity = nn.L1Loss()\n",
    "\n",
    "\n",
    "output_dir = './cyclegan_images'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\assignment2\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\assignment2\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 加载ResNet模型\n",
    "resnet = resnet18(pretrained=True)\n",
    "\n",
    "# 获取全连接层之前的特征提取部分\n",
    "features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "# 定义新的全连接层和ReLU激活函数\n",
    "num_ftrs = resnet.fc.in_features\n",
    "fc_layer = nn.Linear(num_ftrs, 256)\n",
    "relu = nn.ReLU(inplace=True)\n",
    "\n",
    "# 定义模型结构\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, features, fc_layer, relu, num_classes=1000):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        self.features = features\n",
    "        self.fc_layer = fc_layer\n",
    "        self.relu = relu\n",
    "        self.fc_out = nn.Linear(256, num_classes)  # 输出层\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(x.shape)\n",
    "        x = self.fc_layer(x)\n",
    "        print(x.shape)\n",
    "        x = self.relu(x)\n",
    "        print(x.shape)\n",
    "        x = self.fc_out(x)\n",
    "        print(x.shape)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomResNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (fc_layer): Identity()\n",
      "  (relu): Identity()\n",
      "  (fc_out): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# resnet = resnet18(pretrained=True)\n",
    "# num_ftrs = resnet.fc.in_features\n",
    "# resnet.fc = nn.Linear(num_ftrs, 256)\n",
    "# resnet.fc = nn.Linear(32168, 65536)\n",
    "resnet = torch.load(\"models\\\\animal_rec.pth\")\n",
    "resnet.fc_out = torch.nn.Identity()\n",
    "resnet.relu = torch.nn.Identity()\n",
    "resnet.fc_layer = torch.nn.Identity()\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "print(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PerceptualLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PerceptualLoss, self).__init__()\n",
    "        # self.vgg = vgg19(pretrained=True).features[:21]  # 只使用到第三个池化层之前的部分\n",
    "        self.resnet = resnet\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "        # 冻结VGG参数\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, generated, target):\n",
    "        self.resnet = self.resnet.to(device)\n",
    "        gen_features = self.resnet(generated)\n",
    "        target_features = self.resnet(target)\n",
    "\n",
    "        return self.loss(gen_features, target_features)\n",
    "\n",
    "# 实例化感知损失\n",
    "perceptual_loss = PerceptualLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomResNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (fc_layer): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (fc_out): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet1 = torch.load(\"models\\\\animal_rec.pth\")\n",
    "resnet1 = resnet1.to(device)\n",
    "resnet1.fc_out = torch.nn.Identity()\n",
    "resnet1.eval()\n",
    "print(resnet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liu Sicheng\\AppData\\Local\\Temp\\ipykernel_175176\\3968021234.py:31: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  print(loss_G.grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch: 0, Batch: 0, Trained samples: 0, Loss_G: 1.992967963218689, Loss_D_A: 0.35216641426086426\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 总损失\u001b[39;00m\n\u001b[0;32m     29\u001b[0m loss_G \u001b[38;5;241m=\u001b[39m loss_GAN_A2B \u001b[38;5;241m+\u001b[39m loss_cycle_BAB \u001b[38;5;241m+\u001b[39m loss_perceptual\n\u001b[1;32m---> 30\u001b[0m \u001b[43mloss_G\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss_G\u001b[38;5;241m.\u001b[39mgrad)\n\u001b[0;32m     32\u001b[0m optimizer_G\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\assignment2\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\assignment2\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    for i, (real_A, real_B) in enumerate(train_dataloader):\n",
    "        real_A = real_A.to(device)\n",
    "        real_B = real_B.to(device)\n",
    "\n",
    "        # 训练生成器 G_A 和 G_B\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # 对抗性损失\n",
    "        real_A_feature = resnet1(real_A)\n",
    "        # print(real_A_feature.shape)\n",
    "\n",
    "        real_A_feature = real_A_feature.unsqueeze(1).unsqueeze(1).expand(-1,-1,256,256)\n",
    "        real_A_feature = real_A_feature.view(-1,1,256,256)\n",
    "        # print(real_A_feature.shape)\n",
    "        real_A_with_feature = torch.cat([real_A,real_A_feature],dim=1)\n",
    "        # print(real_A_with_feature.shape)\n",
    "        fake_A = G_AA(real_A_with_feature)\n",
    "        \n",
    "        pred_fake = D_A(fake_A)\n",
    "        loss_GAN_A2B = criterion_GAN(pred_fake, torch.ones_like(pred_fake))\n",
    "        loss_perceptual = perceptual_loss(fake_A,real_A)\n",
    "\n",
    "        \n",
    "        # 循环一致性损失\n",
    "        loss_cycle_BAB = criterion_cycle(fake_A, real_A) * 10.0\n",
    "\n",
    "        # 总损失\n",
    "        loss_G = loss_GAN_A2B + loss_cycle_BAB + loss_perceptual\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # 训练判别器 D_A\n",
    "        optimizer_D_A.zero_grad()\n",
    "\n",
    "        pred_real = D_A(real_A)\n",
    "        loss_D_real = criterion_GAN(pred_real, torch.ones_like(pred_real))\n",
    "\n",
    "        pred_fake = D_A(fake_A.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, torch.zeros_like(pred_fake))\n",
    "\n",
    "        # 总损失\n",
    "        loss_D_A = (loss_D_real + loss_D_fake) * 0.5\n",
    "        loss_D_A.backward()\n",
    "        optimizer_D_A.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f'Epoch: {epoch}, Batch: {i}, Trained samples: {i*16}, Loss_G: {loss_G.item()}, Loss_D_A: {loss_D_A.item()}')\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     # 使用测试集中的数据生成图像\n",
    "    #     for i, (real_A, real_B) in enumerate(test_dataloader):\n",
    "    #         real_A = real_A.to(device)\n",
    "    #         real_A_feature = resnet(real_A)\n",
    "    #         real_A_feature = real_A_feature.unsqueeze(1).unsqueeze(1).expand(-1,-1,256,256)\n",
    "    #         real_A_with_feature = torch.cat([real_A,real_A_feature],dim=1)\n",
    "    #         fake_A = G_AA(real_A_with_feature)\n",
    "    #         vutils.save_image(fake_A, f'{output_dir}/fake_B_epoch_{epoch}_batch_{i}.png', normalize=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at models\\Generator_PerceptualLoss_withfeature.ckpt\n"
     ]
    }
   ],
   "source": [
    "save_model_path='models'\n",
    "checkpoint_path = os.path.join(save_model_path, \"Generator_PerceptualLoss_withfeature.ckpt\")\n",
    "torch.save(G_AA.state_dict(), checkpoint_path)\n",
    "print(\"Model saved at %s\" % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_AA = Generator(input_nc=4, output_nc=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (initial_conv): Sequential(\n",
       "    (0): Conv2d(4, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (downsample_blocks): ModuleList(\n",
       "    (0): DownsampleBlock(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): DownsampleBlock(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (residual_blocks): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (6): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (7): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (8): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (upsample_blocks): ModuleList(\n",
       "    (0): UpsampleBlock(\n",
       "      (conv): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "      (norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): UpsampleBlock(\n",
       "      (conv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "      (norm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (output_conv): Sequential(\n",
       "    (0): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (1): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_AA.load_state_dict(torch.load(\"models\\Generator_PerceptualLoss_withfeature.ckpt\"))\n",
    "G_AA.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),  # 根据你的模型调整尺寸\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    image = transform(image).unsqueeze(0)  # 添加批次维度\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image1,image2=None):\n",
    "    # image1 = load_image(image_path1).to(device)\n",
    "    # image2 = load_image(image_path2).to(device)\n",
    "\n",
    "    model= model.to(device)\n",
    "    for i in range(10):\n",
    "        with torch.no_grad():  # 不计算梯度\n",
    "            image=image1*(i/10)+image2*(1-i/10)\n",
    "            output = model(image)\n",
    "            vutils.save_image(output, f'test4 {i}.png', normalize=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = load_image('human_dog\\\\testA\\\\200601.jpg').to(device)\n",
    "image2 = load_image('human_dog\\\\testB\\\\flickr_dog_000079.jpg').to(device)\n",
    "\n",
    "image1_feature = resnet1(image1)\n",
    "image1_feature = image1_feature.unsqueeze(1).unsqueeze(1).expand(-1,-1,256,256)\n",
    "image1_with_feature = torch.cat([image1,image1_feature],dim=1)\n",
    "\n",
    "image2_feature = resnet1(image2)\n",
    "image2_feature = image2_feature.unsqueeze(1).unsqueeze(1).expand(-1,-1,256,256)\n",
    "image2_with_feature = torch.cat([image2,image2_feature],dim=1)\n",
    "\n",
    "output_image = predict(G_AA,image1_with_feature ,image2_with_feature)\n",
    "# output_image = output_image - output_image.min()\n",
    "# output_image = output_image / output_image.max()\n",
    "\n",
    "# output_image = output_image.squeeze()  # 假设输出是图像格式，调整通道\n",
    "# output_image = output_image.permute(1,2,0)\n",
    "# output_image=output_image.to('cpu')\n",
    "# # 步骤 5: 可视化输出图像\n",
    "# plt.imshow(output_image.numpy())\n",
    "# plt.title('Output Image')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(output_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
